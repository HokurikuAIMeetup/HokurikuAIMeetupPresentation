{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_HANDS_ON",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOx0dUxHiLK5thnhte9UnEZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ydaigo/BERT_HANDSON/blob/master/BERT_HANDS_ON.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjFfNfy8IHvx",
        "colab_type": "text"
      },
      "source": [
        "# BERTのハンズオン\n",
        "[transformers](https://github.com/huggingface/transformers)を動かします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3LfNzvnQM09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#準備\n",
        "!pip install transformers\n",
        "!pip install mecab-python3\n",
        "from transformers import pipeline,AutoTokenizer,BertTokenizer,AutoModelForSequenceClassification,BertJapaneseTokenizer, BertForMaskedLM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fBXGO1e3PB0",
        "colab_type": "text"
      },
      "source": [
        "## トークンナイザー\n",
        "トークンナイザーは文章を単語ごとに分割し数字を割り当てる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzt_9s6F4Psl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertJapaneseTokenizer.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')\n",
        "sequence = \"私はエンジニアである。\"\n",
        "tokenized_sequence = tokenizer.tokenize(sequence)\n",
        "print(tokenized_sequence)\n",
        "encoded_sequence = tokenizer.encode(sequence)\n",
        "print(encoded_sequence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfx57QgNKpbF",
        "colab_type": "text"
      },
      "source": [
        "#感情分類\n",
        "感情判定のモデルです。  \n",
        "0:ポジティブ\n",
        "1:ネガティブ\n",
        "\n",
        "[bert-base-japanese-char-whole-word-masking](https://huggingface.co/bert-base-japanese-char-whole-word-masking)というモデルを自作データセットでファインチューニングをしました。  \n",
        "[ファインチューニングしたモデル](daigo/bert-base-japanese-sentiment)\n",
        "\n",
        "[このサイト](https://qiita.com/kenta1984/items/7f3a5d859a15b20657f3)を参考にしました。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBDxEkpxKHwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained('daigo/bert-base-japanese-sentiment') \n",
        "tokenizer = BertJapaneseTokenizer.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')\n",
        "nlp = pipeline(\"sentiment-analysis\",model=model,tokenizer=tokenizer)\n",
        "print(nlp(\"私は幸せである。\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElWK7KTOyF-6",
        "colab_type": "text"
      },
      "source": [
        "# バンダイナムコが公開したモデルを使ってみる。\n",
        "[リポジトリ](https://github.com/BandaiNamcoResearchInc/DistilBERT-base-jp?utm_campaign=Weekly%20Kaggle%20News&utm_medium=email&utm_source=Revue%20newsletter)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUTUZnk20mvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = pipeline(\"fill-mask\",model=\"bandainamco-mirai/distilbert-base-japanese\",tokenizer=\"cl-tohoku/bert-base-japanese-whole-word-masking\")\n",
        "nlp(f\"私は北陸のシステムエンジニアだ。私は機械学習を{nlp.tokenizer.mask_token}している。\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcUomm-eP8Fq",
        "colab_type": "text"
      },
      "source": [
        "# いろいろな調整済みの学習済みモデルを使ってみよう。\n",
        "[参考にしたサイト](https://huggingface.co/transformers/usage.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZWs5PoRQGLF",
        "colab_type": "text"
      },
      "source": [
        "###文章要約\n",
        "モデル  \n",
        "bart-large-cnn\n",
        "\n",
        "\n",
        "文章はアナと雪の女王の要約  \n",
        "https://www.imdb.com/title/tt2294629/plotsummary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ndZz4qfqKNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import pipeline\n",
        "text = \"\"\"When the newly crowned Queen Elsa accidentally uses her power to turn things into ice to curse her home in infinite winter,\n",
        "           her sister Anna teams up with a mountain man, his playful reindeer, and a snowman to change the weather condition.\"\"\"\n",
        "summarizer = pipeline(\"summarization\",model=\"bart-large-cnn\")\n",
        "summarizer(text, min_length=5, max_length=30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5gQwW0HhwbC",
        "colab_type": "text"
      },
      "source": [
        "###質問解答\n",
        "モデル  \n",
        "[bert-large-uncased-whole-word-masking-finetuned-squad](https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad)  \n",
        "トークンナイザー  \n",
        "[bert-base-uncased](https://huggingface.co/bert-base-uncased)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzCyn-QfrWBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "nlp = pipeline(\"question-answering\",model=\"distilbert-base-cased-distilled-squad\")\n",
        "\n",
        "context = text\n",
        "print(nlp(question=\"Who is Queen?\", context=context))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "B2axLj2ki4c-"
      },
      "source": [
        "###文章生成  \n",
        "モデル\n",
        "[gpt2](https://huggingface.co/gpt2#)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MbYeL3CtQBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "model = AutoModelWithLMHead.from_pretrained(\"gpt2\")\n",
        "\n",
        "sequence = f\"I am System Engineer. But\"\n",
        "\n",
        "input = tokenizer.encode(sequence, return_tensors=\"pt\")\n",
        "generated = model.generate(input, max_length=500, do_sample=True)\n",
        "\n",
        "resulting_string = tokenizer.decode(generated.tolist()[0])\n",
        "print(resulting_string)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ft9Ajsa0aQ0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atySL-L0Xlym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}